{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula prática 3 - Validação cruzada.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3_rYa7Vw_E7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "27f9af95-b2f0-47d8-fb47-415bbe7417b9"
      },
      "source": [
        "#importando as bibliotecas\n",
        "from sklearn.datasets import load_wine\n",
        "wine = load_wine()\n",
        "\n",
        "#Exemplo de acesso aos dados\n",
        "X = wine.data[:, :]#Features de cada elemento\n",
        "y = wine.target #Classes de cada elemento\n",
        "\n",
        "#-------------\n",
        "# É preciso terinar o classificador, e testar o seu desempenho com dados \"novos\"\n",
        "# Aqui, dividimos os dados em treino e teste, para podermos testar nosso desempenho depois.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "#O uso dessa função facilita, mas não é obrigatório. Você pode dividir os seus dados manualmente.\n",
        "\n",
        "#_____________\n",
        "#Carregando e treinando os classificadores\n",
        "# Random forests\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train,y_train)\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# Métricas do Random forests\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "\n",
        "rfc_acc = round(accuracy_score(y_test, y_pred), 6)#round é para arredondar\n",
        "rfc_recall = round(recall_score(y_test, y_pred, average='weighted'),6)\n",
        "rcf_precision = round(precision_score(y_test, y_pred, average='weighted'),6)\n",
        "\n",
        "#--------------------------\n",
        "# KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Faz a instanciação do nosso classificador\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "# Faz o treino do modelo\n",
        "knn.fit(X_train, y_train)\n",
        "# testa o modelo\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Métricas do KNN - mede a qualidade\n",
        "knn_acc = round(accuracy_score(y_test, y_pred), 6)#round é para arredondar\n",
        "knn_recall = round(recall_score(y_test, y_pred, average='weighted'),6)\n",
        "knn_precision = round(precision_score(y_test, y_pred, average='weighted'),6)\n",
        "\n",
        "# ---------------------\n",
        "# Comparação\n",
        "print(\"KNN vs Random Forestts\\n\")\n",
        "print(\"Classes: {0}\\n\".format(wine.target_names))\n",
        "print(\"Acurácia: {0} vs {1}\".format(knn_acc, rfc_acc))\n",
        "print(\"Recall: {0} vs {1}\".format(knn_recall, rfc_recall))\n",
        "print(\"Precision: {0} vs {1}\".format(knn_precision, rcf_precision))\n",
        "\n",
        "# ---------------\n",
        "# Na validação cruzada\n",
        "from sklearn.model_selection import cross_val_score\n",
        "cv_rfc = cross_val_score(rfc, X, y)\n",
        "cv_knn = cross_val_score(knn, X, y)\n",
        "print(\"\\nValidação cruzada: {0} vs {1}\".format(cv_knn, cv_rfc))\n",
        "\n",
        "# Soma das validações cruzadas\n",
        "sum_cv_rfc = 0\n",
        "for cv_score in cv_rfc:\n",
        "  sum_cv_rfc += cv_score\n",
        "\n",
        "print(\"\\nResultado Random Forest: {0}\".format(sum_cv_rfc/5))\n",
        "\n",
        "# Soma das validações cruzadas\n",
        "sum_cv_knn = 0\n",
        "for cv_score in cv_knn:\n",
        "  sum_cv_knn += cv_score\n",
        "\n",
        "print(\"\\nResultado KNN: {0}\".format(sum_cv_knn/5))\n",
        "\n",
        "# --------------------------\n",
        "# Buscando hiper parâmetros\n",
        "# faz a validação cruzada dos 2 modelos\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# RFC\n",
        "parameters = {'min_samples_split':(2,6)}\n",
        "rfc_hps = GridSearchCV(rfc, parameters)\n",
        "rfc_hps.fit(X, y)\n",
        "print(\"\\nMelhor valor para min_samples_split: {0}\".format(rfc_hps.best_params_['min_samples_split']))\n",
        "\n",
        "# KNN\n",
        "parameters = {'n_neighbors':(1,20)}\n",
        "knn_hps = GridSearchCV(knn, parameters)\n",
        "knn_hps.fit(X, y)\n",
        "knn_hps.best_params_['n_neighbors']\n",
        "print(\"\\nMelhor valor n_neighbors: {0}\".format(knn_hps.best_params_['n_neighbors']))\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN vs Random Forestts\n",
            "\n",
            "Classes: ['class_0' 'class_1' 'class_2']\n",
            "\n",
            "Acurácia: 0.694915 vs 1.0\n",
            "Recall: 0.694915 vs 1.0\n",
            "Precision: 0.698231 vs 1.0\n",
            "\n",
            "Validação cruzada: [0.63888889 0.69444444 0.66666667 0.65714286 0.85714286] vs [0.97222222 0.94444444 1.         1.         1.        ]\n",
            "\n",
            "Resultado Random Forest: 0.9833333333333332\n",
            "\n",
            "Resultado KNN: 0.7028571428571428\n",
            "\n",
            "Melhor valor para min_samples_split: 2\n",
            "\n",
            "Melhor valor n_neighbors: 1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}